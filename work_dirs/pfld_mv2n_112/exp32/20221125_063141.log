2022-11-25 06:31:41,507 - mmpose - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA A100-PCIE-40GB
CUDA_HOME: /usr
NVCC: Cuda compilation tools, release 10.1, V10.1.24
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.6.2
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 10.1
MMPose: 0.29.0+c314105
------------------------------------------------------------

2022-11-25 06:31:41,592 - mmpose - INFO - Distributed training: False
2022-11-25 06:31:41,653 - mmpose - INFO - Config:
checkpoint_config = dict(interval=1)
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
log_level = 'INFO'
load_from = None
resume_from = None
dist_params = dict(backend='nccl')
workflow = [('train', 1)]
opencv_num_threads = 1
mp_start_method = 'fork'
custom_imports = dict(
    imports=['models', 'datasets'], allow_failed_imports=False)
model = dict(
    type='PFLD',
    backbone=dict(type='PFLDInference'),
    loss_cfg=dict(type='PFLDLoss'))
train_pipeline = [
    dict(type='Resize', height=112, width=112, interpolation=0),
    dict(type='ColorJitter', brightness=0.3, p=0.5),
    dict(type='MedianBlur', blur_limit=3, p=0.3),
    dict(type='HorizontalFlip'),
    dict(type='VerticalFlip'),
    dict(type='Rotate'),
    dict(type='Affine', translate_percent=[0.05, 0.1], p=0.6)
]
val_pipeline = [dict(type='Resize', height=112, width=112)]
dataset_type = 'MeterData'
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='MeterData',
        data_root='/home/dq/gitlab/datasets/table',
        index_file='train_data/annotations.txt',
        pipeline=[
            dict(type='Resize', height=112, width=112, interpolation=0),
            dict(type='ColorJitter', brightness=0.3, p=0.5),
            dict(type='MedianBlur', blur_limit=3, p=0.3),
            dict(type='HorizontalFlip'),
            dict(type='VerticalFlip'),
            dict(type='Rotate'),
            dict(type='Affine', translate_percent=[0.05, 0.1], p=0.6)
        ]),
    val=dict(
        type='MeterData',
        data_root='/home/dq/gitlab/datasets/table',
        index_file='test_data/annotations.txt',
        pipeline=[dict(type='Resize', height=112, width=112)],
        test_mode=True),
    test=dict(
        type='MeterData',
        data_root='/home/dq/gitlab/datasets/table',
        index_file='test_data/annotations.txt',
        pipeline=[dict(type='Resize', height=112, width=112)],
        test_mode=True))
evaluation = dict(save_best='loss')
optimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.99), weight_decay=1e-06)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=400,
    warmup_ratio=0.0001,
    step=[440, 490])
total_epochs = 500
find_unused_parameters = True
work_dir = '/home/dq/github/edgelab/work_dirs/pfld_mv2n_112/exp32'
auto_resume = False
gpu_ids = [0]

2022-11-25 06:31:41,653 - mmpose - INFO - Set random seed to 1081195093, deterministic: False
2022-11-25 06:31:46,504 - mmpose - INFO - Start running, host: dq@stu, work_dir: /home/dq/github/edgelab/work_dirs/pfld_mv2n_112/exp32
2022-11-25 06:31:46,505 - mmpose - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-25 06:31:46,505 - mmpose - INFO - workflow: [('train', 1)], max: 500 epochs
2022-11-25 06:31:46,505 - mmpose - INFO - Checkpoints will be saved to /home/dq/github/edgelab/work_dirs/pfld_mv2n_112/exp32 by HardDiskBackend.
2022-11-25 06:31:49,084 - mmpose - INFO - Epoch [1][5/325]	lr: 1.010e-06, eta: 23:15:57, time: 0.515, data_time: 0.444, memory: 145, loss: 0.2423, grad_norm: 13.7435
2022-11-25 06:31:49,340 - mmpose - INFO - Epoch [1][10/325]	lr: 2.260e-06, eta: 12:46:45, time: 0.051, data_time: 0.001, memory: 145, loss: 0.2748, grad_norm: 14.9732
2022-11-25 06:31:49,608 - mmpose - INFO - Epoch [1][15/325]	lr: 3.510e-06, eta: 9:19:49, time: 0.054, data_time: 0.001, memory: 145, loss: 0.2503, grad_norm: 14.6918
2022-11-25 06:31:49,864 - mmpose - INFO - Epoch [1][20/325]	lr: 4.760e-06, eta: 7:34:40, time: 0.051, data_time: 0.001, memory: 145, loss: 0.2354, grad_norm: 14.0764
2022-11-25 06:31:50,147 - mmpose - INFO - Epoch [1][25/325]	lr: 6.009e-06, eta: 6:34:19, time: 0.056, data_time: 0.000, memory: 145, loss: 0.2380, grad_norm: 13.6506
2022-11-25 06:31:50,424 - mmpose - INFO - Epoch [1][30/325]	lr: 7.259e-06, eta: 5:53:36, time: 0.055, data_time: 0.000, memory: 145, loss: 0.2356, grad_norm: 14.5944
2022-11-25 06:31:50,716 - mmpose - INFO - Epoch [1][35/325]	lr: 8.509e-06, eta: 5:25:33, time: 0.058, data_time: 0.001, memory: 145, loss: 0.2241, grad_norm: 13.7634
2022-11-25 06:31:51,008 - mmpose - INFO - Epoch [1][40/325]	lr: 9.759e-06, eta: 5:04:41, time: 0.059, data_time: 0.001, memory: 145, loss: 0.1959, grad_norm: 12.8050
2022-11-25 06:31:51,314 - mmpose - INFO - Epoch [1][45/325]	lr: 1.101e-05, eta: 4:49:11, time: 0.061, data_time: 0.001, memory: 145, loss: 0.1728, grad_norm: 12.6758
2022-11-25 06:31:51,579 - mmpose - INFO - Epoch [1][50/325]	lr: 1.226e-05, eta: 4:34:35, time: 0.053, data_time: 0.001, memory: 145, loss: 0.1915, grad_norm: 13.2461
2022-11-25 06:31:51,852 - mmpose - INFO - Epoch [1][55/325]	lr: 1.351e-05, eta: 4:23:06, time: 0.055, data_time: 0.001, memory: 145, loss: 0.1685, grad_norm: 12.3951
2022-11-25 06:31:52,116 - mmpose - INFO - Epoch [1][60/325]	lr: 1.476e-05, eta: 4:13:06, time: 0.053, data_time: 0.000, memory: 145, loss: 0.1480, grad_norm: 12.4893
2022-11-25 06:31:52,388 - mmpose - INFO - Epoch [1][65/325]	lr: 1.601e-05, eta: 4:04:56, time: 0.054, data_time: 0.000, memory: 145, loss: 0.1289, grad_norm: 12.0910
2022-11-25 06:31:52,696 - mmpose - INFO - Epoch [1][70/325]	lr: 1.726e-05, eta: 3:59:20, time: 0.062, data_time: 0.001, memory: 145, loss: 0.1198, grad_norm: 11.4976
2022-11-25 06:31:52,994 - mmpose - INFO - Epoch [1][75/325]	lr: 1.851e-05, eta: 3:54:05, time: 0.059, data_time: 0.001, memory: 145, loss: 0.1008, grad_norm: 10.5439
2022-11-25 06:31:53,269 - mmpose - INFO - Epoch [1][80/325]	lr: 1.976e-05, eta: 3:48:47, time: 0.055, data_time: 0.001, memory: 145, loss: 0.0890, grad_norm: 10.1634
2022-11-25 06:31:53,566 - mmpose - INFO - Epoch [1][85/325]	lr: 2.101e-05, eta: 3:44:48, time: 0.059, data_time: 0.001, memory: 145, loss: 0.0807, grad_norm: 10.7709
2022-11-25 06:31:53,852 - mmpose - INFO - Epoch [1][90/325]	lr: 2.226e-05, eta: 3:40:53, time: 0.057, data_time: 0.001, memory: 145, loss: 0.0621, grad_norm: 9.1617
2022-11-25 06:31:54,130 - mmpose - INFO - Epoch [1][95/325]	lr: 2.351e-05, eta: 3:37:12, time: 0.056, data_time: 0.000, memory: 145, loss: 0.0515, grad_norm: 9.3009
2022-11-25 06:31:54,446 - mmpose - INFO - Epoch [1][100/325]	lr: 2.476e-05, eta: 3:34:49, time: 0.063, data_time: 0.001, memory: 145, loss: 0.0538, grad_norm: 8.5987
2022-11-25 06:31:54,739 - mmpose - INFO - Epoch [1][105/325]	lr: 2.601e-05, eta: 3:32:11, time: 0.059, data_time: 0.001, memory: 145, loss: 0.0468, grad_norm: 7.4530
2022-11-25 06:31:55,026 - mmpose - INFO - Epoch [1][110/325]	lr: 2.726e-05, eta: 3:29:35, time: 0.057, data_time: 0.001, memory: 145, loss: 0.0455, grad_norm: 7.9290
2022-11-25 06:31:55,309 - mmpose - INFO - Epoch [1][115/325]	lr: 2.851e-05, eta: 3:27:07, time: 0.056, data_time: 0.001, memory: 145, loss: 0.0447, grad_norm: 8.2291
2022-11-25 06:31:55,577 - mmpose - INFO - Epoch [1][120/325]	lr: 2.976e-05, eta: 3:24:32, time: 0.054, data_time: 0.001, memory: 145, loss: 0.0457, grad_norm: 8.3493
2022-11-25 06:31:55,837 - mmpose - INFO - Epoch [1][125/325]	lr: 3.101e-05, eta: 3:21:58, time: 0.052, data_time: 0.000, memory: 145, loss: 0.0491, grad_norm: 8.7423
2022-11-25 06:31:56,117 - mmpose - INFO - Epoch [1][130/325]	lr: 3.226e-05, eta: 3:20:01, time: 0.056, data_time: 0.001, memory: 145, loss: 0.0469, grad_norm: 8.5266
2022-11-25 06:31:56,403 - mmpose - INFO - Epoch [1][135/325]	lr: 3.351e-05, eta: 3:18:20, time: 0.057, data_time: 0.001, memory: 145, loss: 0.0396, grad_norm: 7.4519
2022-11-25 06:31:56,695 - mmpose - INFO - Epoch [1][140/325]	lr: 3.476e-05, eta: 3:16:54, time: 0.059, data_time: 0.001, memory: 145, loss: 0.0477, grad_norm: 8.6592
2022-11-25 06:31:56,983 - mmpose - INFO - Epoch [1][145/325]	lr: 3.601e-05, eta: 3:15:29, time: 0.058, data_time: 0.001, memory: 145, loss: 0.0410, grad_norm: 6.8523
2022-11-25 06:31:57,273 - mmpose - INFO - Epoch [1][150/325]	lr: 3.726e-05, eta: 3:14:11, time: 0.058, data_time: 0.001, memory: 145, loss: 0.0528, grad_norm: 9.2901
2022-11-25 06:31:57,552 - mmpose - INFO - Epoch [1][155/325]	lr: 3.851e-05, eta: 3:12:47, time: 0.056, data_time: 0.000, memory: 145, loss: 0.0384, grad_norm: 7.3182
2022-11-25 06:31:57,818 - mmpose - INFO - Epoch [1][160/325]	lr: 3.976e-05, eta: 3:11:14, time: 0.053, data_time: 0.000, memory: 145, loss: 0.0390, grad_norm: 7.3787
2022-11-25 06:31:58,073 - mmpose - INFO - Epoch [1][165/325]	lr: 4.101e-05, eta: 3:09:37, time: 0.051, data_time: 0.001, memory: 145, loss: 0.0476, grad_norm: 8.2915
2022-11-25 06:31:58,354 - mmpose - INFO - Epoch [1][170/325]	lr: 4.226e-05, eta: 3:08:31, time: 0.056, data_time: 0.001, memory: 145, loss: 0.0435, grad_norm: 7.6018
2022-11-25 06:31:58,613 - mmpose - INFO - Epoch [1][175/325]	lr: 4.351e-05, eta: 3:07:09, time: 0.052, data_time: 0.000, memory: 145, loss: 0.0444, grad_norm: 7.7053
2022-11-25 06:31:58,872 - mmpose - INFO - Epoch [1][180/325]	lr: 4.476e-05, eta: 3:05:49, time: 0.052, data_time: 0.000, memory: 145, loss: 0.0413, grad_norm: 7.5338
2022-11-25 06:31:59,131 - mmpose - INFO - Epoch [1][185/325]	lr: 4.601e-05, eta: 3:04:34, time: 0.052, data_time: 0.000, memory: 145, loss: 0.0465, grad_norm: 8.1113
