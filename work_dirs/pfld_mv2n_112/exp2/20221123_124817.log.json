{"env_info": "sys.platform: linux\nPython: 3.8.0 (default, Nov  6 2019, 21:49:08) [GCC 7.3.0]\nCUDA available: True\nGPU 0: NVIDIA A100-PCIE-40GB\nCUDA_HOME: /usr\nNVCC: Cuda compilation tools, release 10.1, V10.1.24\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.10.0+cu113\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX512\n  - CUDA Runtime 11.3\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.2\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.11.1+cu113\nOpenCV: 4.6.0\nMMCV: 1.6.2\nMMCV Compiler: GCC 9.4\nMMCV CUDA Compiler: 10.1\nMMPose: 0.29.0+e05eca2", "config": "checkpoint_config = dict(interval=1)\nlog_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\nlog_level = 'INFO'\nload_from = None\nresume_from = None\ndist_params = dict(backend='nccl')\nworkflow = [('train', 1)]\nopencv_num_threads = 1\nmp_start_method = 'fork'\ncustom_imports = dict(\n    imports=['models', 'datasets'], allow_failed_imports=False)\nmodel = dict(\n    type='PFLD',\n    backbone=dict(type='PFLDInference'),\n    loss_cfg=dict(type='PFLDLoss'))\ndataset_type = 'MeterData'\ndata = dict(\n    samples_per_gpu=16,\n    workers_per_gpu=2,\n    train=dict(\n        type='MeterData',\n        index_file='/home/dq/gitlab/datasets/table/train_data/list_d.txt',\n        transform=True),\n    val=dict(\n        type='MeterData',\n        index_file='/home/dq/gitlab/datasets/table/test_data/list_d.txt',\n        transform=False),\n    test=dict(\n        type='MeterData',\n        index_file='/home/dq/gitlab/datasets/table/test_data/list_d.txt',\n        transform=False))\nevaluation = dict(save_best='loss')\noptimizer = dict(type='Adam', lr=0.0001, betas=(0.9, 0.99), weight_decay=1e-06)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=400,\n    warmup_ratio=0.0001,\n    step=[440, 490])\ntotal_epochs = 500\nfind_unused_parameters = True\nwork_dir = '/home/dq/github/edgelab/work_dirs/pfld_mv2n_112/exp2'\nauto_resume = False\ngpu_ids = [0]\n", "seed": 800082441, "exp_name": "pfld_mv2n_112.py", "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 5, "lr": 0.0, "memory": 145, "data_time": 0.46953, "loss": 0.39086, "grad_norm": 25.17636, "time": 0.54877}
{"mode": "train", "epoch": 1, "iter": 10, "lr": 0.0, "memory": 145, "data_time": 0.00064, "loss": 0.38069, "grad_norm": 26.14185, "time": 0.05702}
{"mode": "train", "epoch": 1, "iter": 15, "lr": 0.0, "memory": 145, "data_time": 0.00048, "loss": 0.402, "grad_norm": 26.91861, "time": 0.05716}
{"mode": "train", "epoch": 1, "iter": 20, "lr": 0.0, "memory": 145, "data_time": 0.00049, "loss": 0.38265, "grad_norm": 26.64248, "time": 0.05643}
{"mode": "train", "epoch": 1, "iter": 25, "lr": 1e-05, "memory": 145, "data_time": 0.00076, "loss": 0.39073, "grad_norm": 25.53064, "time": 0.05718}
{"mode": "train", "epoch": 1, "iter": 30, "lr": 1e-05, "memory": 145, "data_time": 0.00048, "loss": 0.36424, "grad_norm": 24.44307, "time": 0.05596}
{"mode": "train", "epoch": 1, "iter": 35, "lr": 1e-05, "memory": 145, "data_time": 0.00045, "loss": 0.3598, "grad_norm": 24.17871, "time": 0.05632}
{"mode": "train", "epoch": 1, "iter": 40, "lr": 1e-05, "memory": 145, "data_time": 0.00049, "loss": 0.35336, "grad_norm": 26.24877, "time": 0.05903}
{"mode": "train", "epoch": 1, "iter": 45, "lr": 1e-05, "memory": 145, "data_time": 0.0005, "loss": 0.27926, "grad_norm": 23.64176, "time": 0.05923}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 1e-05, "memory": 145, "data_time": 0.00056, "loss": 0.25675, "grad_norm": 22.33214, "time": 0.05794}
{"mode": "train", "epoch": 1, "iter": 55, "lr": 1e-05, "memory": 145, "data_time": 0.00061, "loss": 0.3163, "grad_norm": 23.9912, "time": 0.05779}
{"mode": "train", "epoch": 1, "iter": 60, "lr": 1e-05, "memory": 145, "data_time": 0.00049, "loss": 0.23066, "grad_norm": 20.29584, "time": 0.05565}
{"mode": "train", "epoch": 1, "iter": 65, "lr": 2e-05, "memory": 145, "data_time": 0.00089, "loss": 0.2007, "grad_norm": 19.37286, "time": 0.06323}
{"mode": "train", "epoch": 1, "iter": 70, "lr": 2e-05, "memory": 145, "data_time": 0.00065, "loss": 0.19329, "grad_norm": 19.22884, "time": 0.05668}
{"mode": "train", "epoch": 1, "iter": 75, "lr": 2e-05, "memory": 145, "data_time": 0.00095, "loss": 0.16337, "grad_norm": 18.85522, "time": 0.05608}
{"mode": "train", "epoch": 1, "iter": 80, "lr": 2e-05, "memory": 145, "data_time": 0.00048, "loss": 0.15637, "grad_norm": 16.67598, "time": 0.06159}
{"mode": "train", "epoch": 1, "iter": 85, "lr": 2e-05, "memory": 145, "data_time": 0.00059, "loss": 0.1589, "grad_norm": 18.79945, "time": 0.0553}
{"mode": "train", "epoch": 1, "iter": 90, "lr": 2e-05, "memory": 145, "data_time": 0.00059, "loss": 0.15622, "grad_norm": 17.80977, "time": 0.05806}
{"mode": "train", "epoch": 1, "iter": 95, "lr": 2e-05, "memory": 145, "data_time": 0.00045, "loss": 0.16661, "grad_norm": 18.19382, "time": 0.05512}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 2e-05, "memory": 145, "data_time": 0.00058, "loss": 0.14869, "grad_norm": 17.0875, "time": 0.05786}
{"mode": "train", "epoch": 1, "iter": 105, "lr": 3e-05, "memory": 145, "data_time": 0.00084, "loss": 0.15904, "grad_norm": 18.78692, "time": 0.05514}
{"mode": "train", "epoch": 1, "iter": 110, "lr": 3e-05, "memory": 145, "data_time": 0.00055, "loss": 0.16586, "grad_norm": 19.07843, "time": 0.05535}
{"mode": "train", "epoch": 1, "iter": 115, "lr": 3e-05, "memory": 145, "data_time": 0.00095, "loss": 0.16175, "grad_norm": 18.00253, "time": 0.05523}
{"mode": "train", "epoch": 1, "iter": 120, "lr": 3e-05, "memory": 145, "data_time": 0.00056, "loss": 0.13784, "grad_norm": 17.7551, "time": 0.05568}
{"mode": "train", "epoch": 1, "iter": 125, "lr": 3e-05, "memory": 145, "data_time": 0.00053, "loss": 0.16102, "grad_norm": 18.48494, "time": 0.05595}
